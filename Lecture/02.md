# Search and Optimization
## Search Space (State Space)
Quiz: 선교사-식인종 강 건너기
- 2인용 배를 타고 강을 건널 때 어디서든 선교사 $\geq$ 식인종
- 문제 해결 즉 목표 상태가 될 때까지
![Search Soace](02-image.png)

## Blind Search
### 1. Depth First Search (깊이 우선 탐색)
- 초기 노드에서 시작하여 **깊이 방향**으로 탐색
- 목표 노드에 도달하면 종료
- 더 이상 진행할 수 없으면, **백트랙킹 (backtracking, 뒤짚어가기)
- 방문한 노드는 재방문하지 않음

![Tree](02-image1.png)
- A B F G C H I N D J O P E K L Q

- 장점:
    - 탐색과정에서 메모리 사용은 선형적으로 증가하여 효율적인 메모리 사용 가능
- 단점:
    - State space tree에서 깊이가 제한되지 않으면 문제 해결 보장 불가
    - 최단 경로 해 탐색 보장 불가
### 2. Breadth First Search (너비 우선 탐색)
- 초기 노드에서 시작하여 **모든 자식 노드**를 **확장**하여 생성
- 목표 노드가 없으면 **단말노드**에서 다시 **자식 노드 확장**

![Tree](02-image1.png)
- A B C D E F G H I J K L M N O P Q

- 장점
    - 해가 존재한다면 반드시 탐색 가능
    - 최적의 해 탐색 가능
- 단점
    - 메모리 사용이 exponential하게 증가

### 3. Iterative Deepening Search (반복적 깊이 심화 탐색)
- **깊이 한계**가 있는 깊이 **우선 탐색**을 **반복적**으로 적용

![Tree](02-image1.png)
- Level 0: A
- Level 1: A B C
- Level 2: A B F G C H I D J E K L M
- Level 3: A B F G C H I N D J O P E K L Q

- 장점
    - 최적의 해 탐색 가능
    - 효율적인 메모리 사용
- 단점
    - 반복적으로 깊이 우선 탐색을 실시함에 따라 비효율성이 존재하나 BFS에 비해 크게 늘지는 않음

### 4. Bidirectional Search (양방향 탐색)
- **초기 노드**와 **목적 노드** 에서 동시에 **BFS** 진행
- 중간에 만나도록 하여 초기 노드에서 목표 노드로의 최단 경로를 찾는 방법
- BFS와 같은 효과, 그러나 적은 수의 노드를 생성함으로 메모리 사용과 시간에서 유리

## Heuristic Search (정보이용 탐색)
- Heuristic: a method of learning or solving problems that allows people to discover things themselves and learn from their own experiences; 신속하게 어림짐작

- Heuristic 비용 추정
    - 현재 위치에서 목적지까지 직선 거리
    - 제자리에 있지 않는 타일의 개수
    - 충돌하는 회수

### 1. Hill Climbing
- 현재 노드에서 휴리스틱에 의한 평가값이 **가장 좋은 이웃 노드** 하나를 확장해 가는 탐색 방법

- Local optimal solution problem -> Different starting point, Iteration

### 2. Best First Search (최상 우선 탐색)
- 확장 중인 노드들 중에서 목표 노드까지 **남은 거리가 가장 짧은 노드**를 확장하여 탐색
- 남은 거리를 정확히 알 수 없으므로 **휴리스틱** 사용

### 3. A* Search
- 목표를 찾는 것 뿐만 아니라 목표 상태로 도달하는데 소요되는 비용을 최소화 필요

$f(n)$: 노드 $n$을 경유하는 전체 비용
    현재 노드 $n$까지 이미 투입된 비용 $g(n)$과 목표 노드까지의 남은 비용 $h(n)$의 함

$$f(n) = g(n) + h(n)$$

$h(n)$: 남은 비용의 정확한 예측 불가
- $\hat{h}(n)$: $h(n)$에 대응하는 휴리스틱 함수 (heuristic function)

$\hat{f}(n)$: 노드 $n$을 경유하는 추정 전제 비용
        
$$\hat{f}(n) = g(n) + \hat{h}(n)$$

- A* 알고리즘은 추정 전체비용 $\hat{f}(n)$을 최소로 하는 노드를 확장해 가는 방법

만일 휴리스틱 함수 모든 $n$에 대해  $\hat{h}(n) ≤ h(n)$, A* 알고리즘은 항상 최적해를 갖게 됨

   - 결국, 휴리스틱 함수 $\hat{h}(n)$을 얼마나 잘 추정하는 지에 따라 A* 알고리즘의 성능 결정

## Search in Game
- Game State Tree: 상대가 있는 게임에서 자신과 상대방의 가능한 게임 상태
- 자신의 순서에서는 최대한 유리한 상태 선택, 상대방 순서에서는 최대한 불리한 상태 선택
- 많은 수를 볼수록 유리

### 1. Mini-Max 알고리즘
- MAX 노드: 자신에 해당하는 노드로 자기에게 유리한 최대값 선택
- MIN 노드: 상대방에 해당하는 노드로 최소값 선택
- 단말 노드부터 위로 올라가면서 최소 (minimum) - 최대 (maximum) 연산을 반복하여 자신이 선택할 수 있는 방법 중 가장 좋은 것은 값을 결정

### 2. $\alpha-\beta$ Pruning
- Mini-Max 알고리즘에서 모든 트리를 탐색할 필요가 있을까?

- 어떤 노드에 값이 있다면 Max node에서 하한 값, Min node에서 상한 값 역할

- 검토할 필요가 없는 부분은 탐색 제외
    - 깊이 우선 탐색으로 MAX노드와 MIN노드의 값을 결정하면서
- $\alpha$ cut-off: MIN 노드의 현재값이 부모노드의 현재 값보다 작거나 같으면, 나머지 자식 노드 탐색 중지

- $\beta$ cut-off: MAX 노드의 현재 값보다 같거나 크면, 나머지 자식 노드 탐색 중지

### 3. Monte Carlo Tree Search
- Monte Carlo Simulation: 난수를 이용하여 함수의 값을 확률적으로 계산하는 알고리즘

- 예) $\pi$값 계산
    - Uniform distribution으로 정사각형내 점 선태
    - 충분히 반복한 후
    -
    - $$\frac{원 안의 샘플 개수} {전체 샘플의 개수} = \frac{\pi}{4}$$

- Mini-Max 알고리즘은 최적의 해를 찾을 수 있으나 모든 게임 트리를 탐색
- $\alpha-\beta$ Pruning은 효율적이지만 여전히 대부분의 게임 트리 탐색 필요

- Monte Carlo Tree Search
    - 랜덤한 게임 플레이를 반복하고 그 결과를 반영하여 최선의 결과를 선택
    - 최적의 해를 보장하지는 않지만 대규모 게임 트리에 적용 가능
    - 제한 시간에 맞추어 탐색 (Random Play -> 탐색 시간이 길 수록 더 나은 결과)

#### Monte Carlo Tree basic idea
- 나와 상대방은 왼쪽과 오른쪽 둘 중 하나 선택 가능
- 게임이 끝날 떄까지 랜덤하게 선택
- 4번 시도했더니 왼쪽 선택 시 2번 이기고 오른쪽 선택 시 2번 패배, 어느 쪽 선택?
- 3번 시도했더니 왼쪽 선택 시 2번 이기고 오른쪽 선택시 1번 패배, 어느 쪽 선택?
    - 왼쪽
    - Exploitation
- 4번 시도했더니 왼쪽 선택 시 2번 이기고 1번 패배, 오른쪽 선택 시 1번 패배, 어느 쪽 선택?
    - Exploration

#### Multi Armed Bandit (MAB) Problem
- n개의 슬롯머신에서 한번에 1개의 슬롯머신만 시도 가능
- 각 슬롯머신은 각각 다른 승률
- 정해진 시간동안 수익을 극대화하려면?

- Greedy, $\epsilon$-Greedy, adaptive $\epsilon$-Greedy
- Upper Confidential Bound (UCB)
- Thomson Sampling

#### Exploitation & Exploration
- 현재의 랜덤 승률이 높은 쪽 (Exploitation)으로 선택할 지 안 가본 노드 (Exploration)를 선택할지 Scoring -> UCT(Upper Confidence Bound for Trees)

$$UCT(v) = \bar{R} + C \sqrt{\frac{2\log_e{n}}{n_v}}$$
- $n_v$: the number of times v was visited
    - if it is 0, UCT is infinite
- n: the number of times visiting the parent of v
- C: weight on exploration
    - higher the value, more significance on exploration
- $\bar{R}$: the average reward of including v
    - exploitation
- $C \sqrt{\frac{2\log_e{n}}{n_v}}$
    - exploration

UCT 값이 높다는 것은 승률이 높거나, 높지는 않아도 탐색해볼 만 한 노드라는 의미
- Example:
$$(4,2) = (visit count, number of wins)$$

(3,2)
- $ UCT(v_1) = \frac{2}{3} + \sqrt{\frac{2\log_e{4}}{3}} = 1.63$

(1, 0)
- $UCT(v_2) = \frac{0}{1} + \sqrt{\frac{2\log_e{4}}{1}} = 1.67$

- UCT decides to choose $v_2$

#### Monte Carlo Tree Search Process
- 다음 수를 선택하기 위해 가능한 많은 시도를 해보고 그 결과에 따라 선택
- 1 try: Selection(선택) -> Expansion(확장) -> Simulation -> Back Propagation(역전파)

##### Selection (선택)
- 현재 노드에서 UCT 값이 가장 큰 child node를 선택하면서 방문하지 않은 child node까지 탐색

##### Expansion (확장)
- 선택된 노드의 child 노드 중 아직 방문하지 않은 노드를 확장
- 아직 방문하지 않은 노드의 UCT 값은 $\infin$

##### Evaluation (평가) / Simulation
- 새롭게 확장된 노드에서 랜덤 플레이 (Monte Carlo Simulation)
- Win: 1(possibly good), Lose: 0(possibly bad)

##### Back Propagation (역전파)
- 선택한 path의 각 노드별로 승률과 방문회수를 업데이트한 후 UCT 값을 다시 계산

#### 알파고의 탐색
- 바둑판 형세 판단을 위해 Monte Carlo Tree Search 사용
    - 다만 Monte Carlo Simulation에서 무작위로 바둑을 두는 것이 아니라, 프로 바둑기사들의 기보를 학습한 확장정책망 (rollout policy network)에서 제시한 확률 분포를 사용
    - **Monte Carlo Tree Search** 결과에 별도로 학습된 **DNN 가치망 (value Network)**을 함께 사용

##### 제약조건 만족문제
- Back Tracking Search
    - DFS와 같이 변수에 허용되는 값을 하나씩 대입해서 만족값이 없으면 이전 단계로 복귀하여 다른 값을 대입

## Optimization (최적화)
- 여러가지 허용되는 값들 중 주어진 기준을 가장 잘 만족하는 것을 선택

### 1. 조합 최적화
ex) Travelling Salesperson Problem
- 경로의 길이를 최소화하는 해는?
- 목적함수: 최소 또는 최대화 하고자 하는 함수
- Genetic Algorithm, Harmonic Search 등 meta heuristic 방법론 사용

### 2. Function Optimization
- 어떤 **목적 함수**(objective function)가 있을 때, 이 함수를 **최대**로 하거나 **최소**로 하는 **변수 값**을 찾는 최적화 문제

- Find $x_1$, $x_2$ which minimizes $f(x_1, x_2) = (x_1 - 1)^2 + {x_2}^2$
- $f(x_1, x_2)$: 목적함수

$$\frac{\partial f(x_1, x_2)}{\partial{x_1}} = 2x_1 - 2 = 0$$
$$x_1 = 1$$

$$\frac{\partial f(x_1, x_2)}{\partial {x_1}} = 2x_2 = 0$$
$$x_2 = 0$$

#### Regression(회귀) 문제의 최적 함수
- 주어진 데이터를 가장 잘 근사 (approximation)하는 함수
- **최소 평균제곱법**(least mean square method): **오차 함수**(error function) 또는 **에너지 함수**(energy function)를 최소로 하는 함수를 찾는 방법

$$E = \frac{1}{2N}\sum_{i=1}^N{(y_i - f(x_i))^2}$$

if
$$y = ax+b$$

Find a, b which minimizes

$$min_{a,b} \frac{1}{2N}\sum_{i=1}^N{(y_i - ax_i - b)^2}$$

#### Gradient Descent Method (경사 하강법)
- 회귀 모델, 신경망 등의 기본 학습 방법
- Local minima (지역해)에 빠질 위험
- Error Function의 gradient 반대 방향으로 움직여 가면서 최적의 파라미터를 찾는 방법
- Gradient: 각 파라미터에 대해 편미분한 백터 $(\frac{\partial E}{\partial a}, \frac{\partial E}{\partial b})$
- 데이터의 입력과 출력을 이용하여 각 파라미터에 대한 gradient를 계산하여 파라미터를 반복적으로 조정

$$a^{(t+1)} = a^{(t)} - \eta\frac{\partial E}{\partial a} $$
- $a^{(t)}$: 현 시점에서 파라미터 a 값
- $\eta$: 학습률 (0 < $\eta$ < 1)